[package]
name = "small_talk_experiments"
version = "0.1.0"
edition = "2021"

[dependencies]
tracing.workspace = true
eyre.workspace = true
thiserror.workspace = true
error_set.workspace = true
self_cell = "1.0.4"
itertools = "0.13.0"

# ML, llama for efficient CPU embeddings
llama-cpp-2 = { git = "https://github.com/utilityai/llama-cpp-rs/", features = [] }
llama-cpp-sys-2 = { git = "https://github.com/utilityai/llama-cpp-rs/", features = [] }
burn = { version = "0.15.0", features = ["autodiff", "wgpu", "train", "ndarray"] }
burn-import = "0.15.0"
ort = { version = "2.0.0-rc.9", features = ["copy-dylibs", "load-dynamic", "cuda", "directml"] }

# Audio stuff
mel_spec = "0.2.7"
rubato = "0.16.1"
hound = "3.5.1"
wavers.workspace = true
fon = { git = "https://github.com/ardaku/fon" }

serde.workspace = true
serde_json.workspace = true