[package]
name = "small_talk_ml"
version = "0.1.0"
edition = "2021"

[lib]
doctest = false
path = "src/lib.rs"

[[bin]]
path = "src/main.rs"
name = "small_talk_ml"

[dependencies]
tracing.workspace = true
eyre.workspace = true
thiserror.workspace = true
error_set.workspace = true
self_cell = "1.0.4"
itertools = "0.13.0"

# ML, llama for efficient CPU embeddings
llama-cpp-2 = { git = "https://github.com/utilityai/llama-cpp-rs", rev = "a103be60d05885fcae99665a397e72ba3533c925", features = [] }
llama-cpp-sys-2 = { git = "https://github.com/utilityai/llama-cpp-rs", rev = "a103be60d05885fcae99665a397e72ba3533c925", features = [] }
burn = { version = "0.15.0", features = ["autodiff", "wgpu", "train", "ndarray"] }
burn-import = "0.15.0"

# Audio stuff
mel_spec = "0.2.7"
rubato = "0.16.1"
wavers.workspace = true
fon = { git = "https://github.com/ardaku/fon" }

serde.workspace = true
serde_json.workspace = true