[package]
name = "small_talk_ml"
version = "0.1.0"
edition = "2021"

[lib]
doctest = false
path = "src/lib.rs"

[[bin]]
path = "src/main.rs"
name = "small_talk_ml"

[dependencies]
tracing.workspace = true
eyre.workspace = true
thiserror.workspace = true
error_set.workspace = true
self_cell = "1.0.4"
itertools = "0.13.0"

# ML, llama for efficient CPU embeddings
llama-cpp-2 = { git = "https://github.com/utilityai/llama-cpp-rs/", features = [] }
llama-cpp-sys-2 = { git = "https://github.com/utilityai/llama-cpp-rs/", features = [] }
burn = { version = "0.15.0", features = ["autodiff", "wgpu", "train"] }
burn-import = "0.15.0"

serde.workspace = true
serde_json.workspace = true